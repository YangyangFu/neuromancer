{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a7e6bc-4b3d-419e-9940-22f62b9f115e",
   "metadata": {},
   "source": [
    "# `Component` walkthrough\n",
    "This notebook demonstrates how components work together in NeuroMANCER, and how data flows through the computational graph assembled by the `Problem` class. We'll demonstrate by building a full neural state space model for partially-observable dynamical systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55cb6745-0a8d-4c4a-8bc8-09b8055635c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from neuromancer.estimators import MLPEstimator\n",
    "from neuromancer.dynamics import block_model, BlockSSM\n",
    "from neuromancer.problem import Problem\n",
    "from neuromancer.constraint import Loss\n",
    "from neuromancer.blocks import MLP\n",
    "from neuromancer.plot import plot_model_graph\n",
    "import slim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297dc0d0-6a88-4d49-aaf4-2d3476062c33",
   "metadata": {},
   "source": [
    "We begin constructing our neural SSM by creating a latent state estimator to predict initial conditions from past observations. To do this, we specify the dimensionality of both our observables and the latent state; in this case, we choose 10 and 20, respectively.\n",
    "\n",
    "As you will see after running the cell below, each component has a handy string representation that indicates the name of the component, its input variables, and its outputs. Notice that the outputs of the component are tagged with the name of the component that produced them; this is used to prevent name collisions in the computational graph, and will become important in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "440794d5-ab9f-4ed6-9b5c-c8ac5723988f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "estim(Yp) -> x0_estim, reg_error_estim"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estim = MLPEstimator(\n",
    "    {\"Yp\": (10,), \"x0\": (20,)},\n",
    "    nsteps=2,\n",
    "    name=\"estim\"\n",
    ")\n",
    "estim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e16bb2-1e84-4a36-8a0c-be978dbd28fa",
   "metadata": {},
   "source": [
    "Next, we define our state space model. The SSM component will take the output of the estimator as its initial condition `x0`. However, recall that components tag their outputs with their name. If we look at the default input keys of the `BlockSSM` class, we'll notice a slight problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2562991f-5aaf-4d56-801f-b767388d8783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x0', 'Yf']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BlockSSM.DEFAULT_INPUT_KEYS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f25109-494d-47b0-a1ef-f89635a09a3b",
   "metadata": {},
   "source": [
    "The canonical name for the initial state variable in `BlockSSM`s is named `x0`, not `x0_estim`. Because of this, we need to remap the estimator's output `x0_estim` to `x0`. To do this, we hand a dictionary to the `input_keys` parameter of the `block_model` function which maps the tagged variable to the canonical name used by the dynamics model. The following cell uses the named constructor `block_model` to generate a Block Nonlinear neural SSM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90cbccc5-0811-4187-be06-2c93267dc124",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamics = block_model(\n",
    "    \"blocknlin\",\n",
    "    {\"x0\": (20,), \"Yf\": (10,), \"Uf\": (2,)},\n",
    "    slim.Linear,\n",
    "    MLP,\n",
    "    bias=False,\n",
    "    input_key_map={\"x0\": \"x0_estim\", \"Uf\": \"Uf_renamed\"},\n",
    "    name=\"dynamics\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1336b200-567f-4529-87f6-8bdd2ee30d6c",
   "metadata": {},
   "source": [
    "Now we have both model components ready to compose with a `Problem` instance. However, before we do that, let's pick apart how data flows through the computational graph formed by these components when composed in a `Problem`.\n",
    "\n",
    "First, we'll create a `DataDict` containing the constant inputs required by each component (`Yp`, `Yf`, and `Uf` for the dynamics model; and `Yp` for the estimator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f226ca6-1726-4e47-8b7f-aa18976b4f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Yp\": torch.rand(2, 10, 10),\n",
    "    \"Yf\": torch.rand(2, 10, 10),\n",
    "    \"Uf_renamed\": torch.rand(2, 10, 2),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88056e63-27e4-4b35-95ca-f3c29e856de8",
   "metadata": {},
   "source": [
    "Next, let's push the data through the estimator to see what we receive as output (note that we combine the data and estimator output to retain the constant inputs used by the dynamics model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efe066d6-ccff-49ab-a2a1-42713c590319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Yp', 'Yf', 'Uf_renamed', 'x0_estim', 'reg_error_estim'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = {**data, **estim(data)}\n",
    "output.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbddc346-5f59-4245-a807-9fdc41cc975e",
   "metadata": {},
   "source": [
    "As expected, we obtain our estimated initial state `x0_estim` alongside a `reg_error_estim` term measuring the regularization error incurred by any structured linear maps in the component (in this case there are none).\n",
    "\n",
    "Now let's take the output of the estimator and push it through the SSM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57224cc8-d7ee-4714-bff7-def11bb38706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Yp', 'Yf', 'Uf_renamed', 'x0_estim', 'reg_error_estim', 'fU_dynamics', 'X_pred_dynamics', 'Y_pred_dynamics', 'reg_error_dynamics'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = {**output, **dynamics(output)}\n",
    "output.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c697d376-fefd-4ed2-8290-74450dac6040",
   "metadata": {},
   "source": [
    "As we can see, the dynamics model correctly handles the `x0_estim` variable; internally, the variable is automatically renamed to its canonical name. This capability allows users to combine components in arbitrary ways.\n",
    "\n",
    "We'll next create some objectives and constraints to demonstrate how these interact with components in a `Problem` instance; we define the inputs to each objective and constraint by providing a list of keys which can reference either the input data or the output of any component in the overall model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93d43c91-80d2-4ff1-a125-889becf8529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_loss = Loss([\"Y_pred_dynamics\", \"Yf\"], F.mse_loss, name=\"reference_loss\")\n",
    "estimator_loss = Loss([\"X_pred_dynamics\", \"x0_estim\"], lambda x, y: F.mse_loss(x[-1, :-1, :], y[1:]), name=\"estimator_loss\")\n",
    "bounds_constraint = Loss([\"Y_pred_dynamics\"], lambda x: F.relu(0.5 - x).mean(), name=\"bounds_constraint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa15aac-b9c2-48d5-a130-4cd566c92d76",
   "metadata": {},
   "source": [
    "At last, let's put together a `Problem` class to combine everything. Like `Component`s, when we instantiate a `Problem` we can inspect its string representation to get an overview of all the constructs in the model and see how they are put together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1530815d-ddde-4c48-96ea-6f323a9a0169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "### MODEL SUMMARY ###\n",
       "\n",
       "COMPONENTS:\n",
       "  estim(Yp) -> x0_estim, reg_error_estim\n",
       "  dynamics(Yf, x0_estim, Uf_renamed) -> fU_dynamics, X_pred_dynamics, Y_pred_dynamics, reg_error_dynamics\n",
       "\n",
       "CONSTRAINTS:\n",
       "  bounds_constraint(Y_pred_dynamics) -> <function <lambda> at 0x0000024776ACEF78> * 1.0\n",
       "\n",
       "OBJECTIVES:\n",
       "  reference_loss(Y_pred_dynamics, Yf) -> <function mse_loss at 0x000002475C270708> * 1.0\n",
       "  estimator_loss(X_pred_dynamics, x0_estim) -> <function <lambda> at 0x0000024776AB58B8> * 1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objectives = [reference_loss, estimator_loss]\n",
    "constraints = [bounds_constraint]\n",
    "trainable_components = [estim, dynamics]\n",
    "model = Problem(objectives, constraints, trainable_components)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ab17ab-7f86-4611-a50d-cba7bb74241e",
   "metadata": {},
   "source": [
    "With our `Problem` created, we can now push the data dictionary we previously defined through it to receive the outputs of each component and the values of each objective and constraint we specified. Note that we wrap the data into a `DataDict` and add a `name` attribute; like the attribute used in `Component`s, this is used to prevent name collisions between variables generated by the use of different data splits during training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1629bc58-15b7-408f-bc76-973bf092309f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test_Yp', 'test_Yf', 'test_Uf_renamed', 'test_name', 'test_x0_estim', 'test_reg_error_estim', 'test_fU_dynamics', 'test_X_pred_dynamics', 'test_Y_pred_dynamics', 'test_reg_error_dynamics', 'test_reference_loss', 'test_estimator_loss', 'test_bounds_constraint', 'test_loss'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"name\"] = \"test\"\n",
    "output = model(data)\n",
    "output.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c078dd-7c05-43e3-973b-8566eab4caca",
   "metadata": {},
   "source": [
    "And that's all there is to it. The model can now be passed to a `Trainer` along with a `Dataset` instance to train and validate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5eb8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuromancer2",
   "language": "python",
   "name": "neuromancer2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
